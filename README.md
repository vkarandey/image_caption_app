# Сервис генерации подписи к картинкам (Image Captioning)

Это веб-приложение на Flask, которое генерирует подписи к изображениям с помощью кастомной модели на основе BLIP + дистилляции знаний.
Реализуется обучение модели генерации подписей к изображениям с использованием архитектуры BLIP (Bootstrapped Language-Image Pretraining). Модель обучается в парадигме distillation: меньшая student-модель учится повторять поведение teacher-модели.

## Возможности

- Загрузка изображения через веб-интерфейс
- Генерация описания с помощью обученной модели
- Автоматическая загрузка весов модели с Google Drive

---


## Архитектура и обучение

Teacher-модель: Salesforce/blip-image-captioning-base, заморожена, используется только для генерации логитов.

Student-модель: уменьшенная версия BLIP (6 слоёв в encoder и decoder, уменьшенные размеры скрытых слоёв).

Loss-функция: комбинация CrossEntropyLoss и KLDivLoss. Общая формула: α * CE + (1 - α) * KL, где α = 0.5.

Оптимизатор: AdamW, learning rate = 3e-5.

### Данные

Используется 12 000 изображений из COCO 2017 (train2017).

Размер изображений: 384x384.

Разделение: 80% обучение, 20% валидация.

Датасет обрабатывается через кастомный ImageCaptionDataset.

### Обучение

Обучение проводится до 15 эпох.

На каждой итерации:

1. Учитель генерирует логиты (без вычисления градиентов).

2. Student-модель предсказывает подписи.

3. Вычисляется лосс между предсказаниями студента и учителя/истинными подписями.

4. Выполняется шаг оптимизации.

После каждой эпохи:

1. Сохраняется чекпоинт модели.

2. Вычисляются метрики качества: BLEU, ROUGE, METEOR.

3. Выводятся примеры сгенерированных подписей.
### Метрики

Для оценки используются BLEU, ROUGE и METEOR.

### Сохранение и загрузка модели

Чекпоинты сохраняются в ./checkpoints/student_epoch{n}.pt.
При старте обучения автоматически загружается последний доступный чекпоинт, если он существует.
### Пример генерации подписей

После каждой эпохи выводятся несколько примеров сгенерированных подписей на валидации. 
Пример:

1: a man is playing frisbee in a park

2: a dog is running across a field

3: a person riding a motorcycle on a road

##  Установка

Нужен Python 3.8 или выше.

### 1. Клонирование репозитория

```bash
git clone https://github.com/your-username/your-repo-name.git
cd your-repo-name
```

### 2. Акцивация venv
macOS / Linux:
``` bash
python3 -m venv venv
source venv/bin/activate
```
Windows:
```cmd
python -m venv venv
venv\Scripts\activate
```
### 3. Установка зависимостей
```
pip install -r requirements.txt
```

## Загрузка весов модели

При первом запуске приложение автоматически скачает веса модели `student_epoch6.pt` из Google Drive.

Если это не сработает, вы можете скачать веса вручную:

[Скачать веса модели (Google Drive)](https://drive.google.com/file/d/1w7hY_dpYc-QJ_qUzBkz-2uBqxnfS0lko/view?usp=sharing)

Скачанный файл необходимо поместить в корень проекта рядом с `app.py`.

## Запуск

```bash
python app.py
```
Откройте браузер и перейдите по адресу: http://127.0.0.1:8080

## Структура проекта
```
image_caption_app/
│
├── app.py                  # Flask-приложение
├── student_epoch6.pt       # Вес модели (автоскачивание или вручную)
├── requirements.txt        # Зависимости
├── README.md               # Документация
├── templates/
│   └── index.html          # HTML-шаблон
└── static/
    └── uploaded.jpg        # Сюда сохраняется загруженное изображение
```
